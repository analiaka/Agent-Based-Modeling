{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0083a835-42bd-4bea-9c47-00d9eb64b912",
   "metadata": {},
   "source": [
    "# Introduction\r\n",
    "\r\n",
    "This Jupyter Notebook provides a step-by-step guide to performing preliminary statistical tests, including the **Kaiser-Meyer-Olkin (KMO) Test**, **Bartlett’s Test of Sphericity**, and **Cronbach's Alpha**. These tests are crucial for assessing the suitability of your dataset for **Principal Component Analysis (PCA)**. \r\n",
    "\r\n",
    "- **KMO Test** evaluates the adequacy of sampling by measuring the proportion of variance in variables that could be explained by underlying factors. Higher values (close to 1) indicate that PCA is appropriate.  \r\n",
    "- **Bartlett’s Test of Sphericity** checks whether the correlation matrix of the data is significantly different from an identity matrix, which is a prerequisite for PCA. A significant p-value suggests that the dataset is suitable for dimensionality reduction.  \r\n",
    "- **Cronbach’s Alpha** measures the internal consistency (reliability) of a set of items or variables, ensuring that they are sufficiently correlated to represent a cohesive construct.\r\n",
    "\r\n",
    "By following this notebook, you will learn how to calculate these metrics and interpret their results, ensuring that your dataset meets the assumptions and criteria for performing PCA effectively.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c48217-5726-401f-b8a7-088bffc7112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may need to install the following so check \n",
    "pip install factor-analyzer scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c8b295-0fff-4c29-98fe-59838c049189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required below:\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from factor_analyzer import calculate_kmo\n",
    "from factor_analyzer import calculate_bartlett_sphericity\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6812d2-c2c4-461e-b41d-7c454b63215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "# Set the working directory to the path where your files are located\n",
    "os.chdir('path_to_your_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b230641-e6b8-4f84-9c88-1786cc086931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your existing data (replace 'your_data.csv' with your file path)\n",
    "df = pd.read_csv('your_Data.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0146535-e14a-4c74-8a5f-46f993ff0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the subset of columns for each TPB construct (example: Attitude)\n",
    "attitude_data = df[['Attitude3 Coded', 'Attitude3 Coded', 'Attitude4 Coded', 'Attitude5 Coded', 'Attitude6 Coded',\n",
    "                      'Attitude7 Coded', 'Attitude8 Coded', 'Attitude9 Coded']]\n",
    "\n",
    "# Calculate the KMO test\n",
    "kmo_all, kmo_model = calculate_kmo(attitude_data)\n",
    "print(\"KMO Test Value for Attitude:\", kmo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f03e4-e063-415b-96d8-628ab41d7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Bartlett’s Test for Attitude\n",
    "chi_square_value, p_value = calculate_bartlett_sphericity(attitude_data)\n",
    "print(\"Bartlett’s Test Chi-Square Value:\", chi_square_value)\n",
    "print(\"Bartlett’s Test p-Value:\", p_value)\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"Bartlett's Test is significant (p < 0.05). The data is suitable for factor analysis.\")\n",
    "else:\n",
    "    print(\"Bartlett's Test is not significant (p ≥ 0.05). The data may not be suitable for factor analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ead966-78b7-4ceb-807e-ee20fc23dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Cronbach’s Alpha\n",
    "def cronbach_alpha(df):\n",
    "    items = df.columns\n",
    "    item_scores = df.to_numpy()\n",
    "    item_count = len(items)\n",
    "\n",
    "    variance_items = np.var(item_scores, axis=0, ddof=1)\n",
    "    total_score = item_scores.sum(axis=1)\n",
    "    variance_total = np.var(total_score, ddof=1)\n",
    "\n",
    "    alpha = (item_count / (item_count - 1)) * (1 - (variance_items.sum() / variance_total))\n",
    "    return alpha\n",
    "\n",
    "# Calculate Cronbach’s Alpha for Attitude\n",
    "attitude_alpha = cronbach_alpha(attitude_data)\n",
    "print(\"Cronbach’s Alpha for Attitude:\", attitude_alpha)\n",
    "\n",
    "# Interpretation\n",
    "if attitude_alpha >= 0.7:\n",
    "    print(\"Internal consistency is acceptable (α ≥ 0.7).\")\n",
    "else:\n",
    "    print(\"Internal consistency is questionable (α < 0.7).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8f2d7-a8b4-430e-be2b-466ee9fa59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the subset of columns for each TPB construct (example 2: Social norms)\n",
    "snorms_data = df[['SNorms1 Coded', 'SNorms2 Coded', 'SNorms3 Coded', 'SNorms4 Coded']]\n",
    "\n",
    "# Calculate the KMO test\n",
    "kmo_all, kmo_model = calculate_kmo(snorms_data)\n",
    "print(\"KMO Test Value for Social Norms:\", kmo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9dca76-d0d4-49b1-8fac-a5e82c0b1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Bartlett’s Test for Social norm\n",
    "chi_square_value, p_value = calculate_bartlett_sphericity(snorms_data)\n",
    "print(\"Bartlett’s Test Chi-Square Value:\", chi_square_value)\n",
    "print(\"Bartlett’s Test p-Value:\", p_value)\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"Bartlett's Test is significant (p < 0.05). The data is suitable for factor analysis.\")\n",
    "else:\n",
    "    print(\"Bartlett's Test is not significant (p ≥ 0.05). The data may not be suitable for factor analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4af26b-79df-4f27-95e6-d200bb4c8aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Cronbach’s Alpha\n",
    "def cronbach_alpha(df):\n",
    "    items = df.columns\n",
    "    item_scores = df.to_numpy()\n",
    "    item_count = len(items)\n",
    "\n",
    "    variance_items = np.var(item_scores, axis=0, ddof=1)\n",
    "    total_score = item_scores.sum(axis=1)\n",
    "    variance_total = np.var(total_score, ddof=1)\n",
    "\n",
    "    alpha = (item_count / (item_count - 1)) * (1 - (variance_items.sum() / variance_total))\n",
    "    return alpha\n",
    "\n",
    "# Calculate Cronbach’s Alpha for Attitude\n",
    "snorms_alpha = cronbach_alpha(snorms_data)\n",
    "print(\"Cronbach’s Alpha for Social Norms:\", snorms_alpha)\n",
    "\n",
    "# Interpretation\n",
    "if snorms_alpha >= 0.7:\n",
    "    print(\"Internal consistency is acceptable (α ≥ 0.7).\")\n",
    "else:\n",
    "    print(\"Internal consistency is questionable (α < 0.7).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd06265-b209-4b9d-984d-73c0efd229ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the subset of columns for each TPB construct (example 3: Climate change pereception)\n",
    "ccperc_data = df[['CCPerception1 Coded', 'CCPerception2 Coded', 'CCPerception3 Coded', 'CCPerception4 Coded', 'CCPerception5 Coded', 'CCPerception6 Coded', 'CCPerception7 Coded', 'CCPerception8 Coded', 'CCPerception9 Coded', 'CCPerception10 Coded', 'CCPerception11 Coded', 'CCPerception12 Coded', 'CCPerception13 Coded', 'CCPerception14 Coded']]\n",
    "\n",
    "# Calculate the KMO test\n",
    "kmo_all, kmo_model = calculate_kmo(ccperc_data)\n",
    "print(\"KMO Test Value for Climate Change Perception:\", kmo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4713ed76-8b7d-45c4-9e26-a53cfa8d7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Bartlett’s Test for Climate change pereception\n",
    "chi_square_value, p_value = calculate_bartlett_sphericity(ccperc_data)\n",
    "print(\"Bartlett’s Test Chi-Square Value:\", chi_square_value)\n",
    "print(\"Bartlett’s Test p-Value:\", p_value)\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"Bartlett's Test is significant (p < 0.05). The data is suitable for factor analysis.\")\n",
    "else:\n",
    "    print(\"Bartlett's Test is not significant (p ≥ 0.05). The data may not be suitable for factor analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f847d55-e5f3-4351-9ab7-3319f626671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Cronbach’s Alpha\n",
    "def cronbach_alpha(df):\n",
    "    items = df.columns\n",
    "    item_scores = df.to_numpy()\n",
    "    item_count = len(items)\n",
    "\n",
    "    variance_items = np.var(item_scores, axis=0, ddof=1)\n",
    "    total_score = item_scores.sum(axis=1)\n",
    "    variance_total = np.var(total_score, ddof=1)\n",
    "\n",
    "    alpha = (item_count / (item_count - 1)) * (1 - (variance_items.sum() / variance_total))\n",
    "    return alpha\n",
    "\n",
    "# Calculate Cronbach’s Alpha for Attitude\n",
    "ccperc_alpha = cronbach_alpha(snorms_data)\n",
    "print(\"Cronbach’s Alpha for CLimate Change Perception:\", ccperc_alpha)\n",
    "\n",
    "# Interpretation\n",
    "if ccperc_alpha >= 0.7:\n",
    "    print(\"Internal consistency is acceptable (α ≥ 0.7).\")\n",
    "else:\n",
    "    print(\"Internal consistency is questionable (α < 0.7).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648f246-dcf1-4f15-92e2-490d3b8986ee",
   "metadata": {},
   "source": [
    "Follow the above examples to run the tests for all groups of variables in your data and adjust your analysis accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ea4e9-901a-4184-b651-14d0591a71c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c305774-8845-4429-bd03-b774eb8a1631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
